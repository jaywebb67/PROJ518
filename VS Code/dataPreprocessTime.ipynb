{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","mount_file_id":"1_nRMsynmer3g1LbSzXDeJflxhzM8TEjl","authorship_tag":"ABX9TyOCXCVAUrtORS8eHOoi5fRf"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"P9JOVlB0KDXa","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1756167390269,"user_tz":-60,"elapsed":362317,"user":{"displayName":"jay webb","userId":"02822891855666551694"}},"outputId":"32c08d40-9e6e-427a-b886-21ee464d580b"},"outputs":[{"output_type":"stream","name":"stdout","text":["Total trials: 63850\n","Unique labels: 80\n","→ saved fine0: train=11876, val=250, test=374\n","→ saved fine1: train=11874, val=250, test=376\n","→ saved fine2: train=11688, val=246, test=366\n","→ saved fine3: train=11782, val=248, test=370\n","→ saved fine4: train=11590, val=244, test=366\n"]}],"source":["import os\n","import numpy as np\n","import torch\n","from sklearn.model_selection import train_test_split\n","from scipy.signal import butter, filtfilt, iirnotch, resample\n","\n","# ────────────────────────────────────────────────────────────────\n","# 1) PREPROCESSING HELPERS (no linked‐mastoid reference)\n","# ────────────────────────────────────────────────────────────────\n","\n","def notch_filter(data, sfreq=1000.0, freqs=(50.0,), bandwidth=1.0):\n","    \"\"\"\n","    Zero‐phase notch at `freq` Hz (bandwidth Hz wide).\n","    data: np.ndarray, shape (62, n_samples)\n","    \"\"\"\n","    out = data.copy()\n","    for freq in freqs:\n","        Q = freq / bandwidth\n","        b, a = iirnotch(w0=freq, Q=Q, fs=sfreq)\n","        out = filtfilt(b, a, out, axis=1)\n","    return out\n","\n","def bandpass_filter(data, sfreq=1000.0, low=0.5, high=80.0, order=5):\n","    \"\"\"\n","    Zero‐phase Butterworth bandpass between low and high (Hz).\n","    data: np.ndarray, shape (62, n_samples)\n","    \"\"\"\n","    nyq = sfreq / 2.0\n","    b, a = butter(order, [low/nyq, high/nyq], btype='band')\n","    return filtfilt(b, a, data, axis=1)\n","\n","def crop_window(data, sfreq=1000.0, tmin=0.04, tmax=0.44):\n","    \"\"\"\n","    Crop each trial to [tmin, tmax] seconds.\n","    data: np.ndarray, shape (62, n_samples)\n","    \"\"\"\n","    start = int(np.round(tmin * sfreq))\n","    end   = int(np.round(tmax * sfreq))\n","    return data[:, start:end]\n","\n","def downsample(data, sfreq_old=1000.0, sfreq_new=128.0):\n","    \"\"\"\n","    Fourier‐based resampling from sfreq_old → sfreq_new.\n","    data: np.ndarray, shape (62, n_samples_old)\n","    \"\"\"\n","    n_old = data.shape[1]\n","    n_new = int(np.round(n_old * (sfreq_new / sfreq_old)))\n","    return resample(data, n_new, axis=1)\n","\n","def standardize_dataset(all_trials):\n","    \"\"\"\n","    Compute per‐channel mean/std on training set, then z‐score.\n","    all_trials: np.ndarray, shape (n_trials, 62, n_times)\n","    Returns (standardized, mu, sigma)\n","    \"\"\"\n","    mu    = all_trials.mean(axis=(0, 2), keepdims=True)  # → (1, 62, 1)\n","    sigma = all_trials.std( axis=(0, 2), keepdims=True)  # → (1, 62, 1)\n","    eps = 1e-7\n","    return (all_trials - mu) / (sigma + eps), mu, sigma\n","\n","def car_reference(data):\n","    # data: (62, T)\n","    return data - data.mean(axis=0, keepdims=True)\n","\n","\n","def preprocess_single_trial(raw_data,\n","                            sfreq_raw=1000.0,\n","                            notch_freq=(50.0,100.0,150.0), notch_bw=1.0,\n","                            bp_low=0.5, bp_high=80.0, bp_order=5,\n","                            tmin=0.04, tmax=0.44,\n","                            sfreq_new=250.0):\n","    \"\"\"\n","    Entire preprocessing chain for one trial—ASSUMES raw_data is already mastoid‐referenced:\n","      1. Notch 50 Hz\n","      2. Band‐pass 0.5–80 Hz\n","      3. Crop 40–440 ms\n","      4. Downsample to 250 Hz\n","    raw_data: np.ndarray, shape (62, n_samples_raw)\n","    \"\"\"\n","    # 1) Notch filter\n","    data_notch = notch_filter(raw_data, sfreq=sfreq_raw, freqs=notch_freq, bandwidth=notch_bw)\n","\n","    # 2) Bandpass 0.5–80 Hz\n","    data_bp = bandpass_filter(data_notch, sfreq=sfreq_raw, low=bp_low, high=bp_high, order=bp_order)\n","\n","    data_cr = car_reference(data_bp)\n","\n","    # 3) Crop to 40–440 ms\n","    data_crop = crop_window(data_cr, sfreq=sfreq_raw, tmin=tmin, tmax=tmax)\n","\n","    # 4) Downsample to 128 Hz\n","    data_ds = downsample(data_crop, sfreq_old=sfreq_raw, sfreq_new=sfreq_new)\n","\n","    data_ds_vis = data_ds[vis_idx,:]\n","    return data_ds, data_ds_vis\n","\n","# ────────────────────────────────────────────────────────────────\n","# 2) CHANNEL NAMES (the 62 scalp electrodes are stored)\n","# ────────────────────────────────────────────────────────────────\n","\n","channel_names_62 = [\n","    \"FP1\",\"FPZ\",\"FP2\",\"AF3\",\"AF4\",\n","    \"F7\",\"F5\",\"F3\",\"F1\",\"FZ\",\"F2\",\"F4\",\"F6\",\"F8\",\n","    \"FT7\",\"FC5\",\"FC3\",\"FC1\",\"FCZ\",\"FC2\",\"FC4\",\"FC6\",\"FT8\",\n","    \"T7\",\"C5\",\"C3\",\"C1\",\"CZ\",\"C2\",\"C4\",\"C6\",\"T8\",\n","    # M1, M2 are NOT present—assumed already referenced\n","    \"TP7\",\"CP5\",\"CP3\",\"CP1\",\"CPZ\",\"CP2\",\"CP4\",\"CP6\",\"TP8\",\n","    \"P7\",\"P5\",\"P3\",\"P1\",\"PZ\",\"P2\",\"P4\",\"P6\",\"P8\",\n","    \"PO7\",\"PO5\",\"PO3\",\"POZ\",\"PO4\",\"PO6\",\"PO8\",\n","    \"CB1\",\"O1\",\"OZ\",\"O2\",\"CB2\"\n","]\n","\n","# indices of the four “visual” channels we want to keep\n","vis_chs = [\"T7\",\"T8\",\"TP7\",\"TP8\",\"O1\",\"OZ\",\"O2\",\"P7\",\"P5\",\"P3\",\"P1\",\"PZ\",\"P2\",\"P4\",\"P6\",\"P8\",\"PO7\",\"PO5\",\"PO3\",\"POZ\",\"PO4\",\"PO6\",\"PO8\"]\n","vis_idx = [channel_names_62.index(ch) for ch in vis_chs]\n","\n","def segment_windows(epoch, win=64, hop=32):\n","    n_chans, n_times = epoch.shape\n","    windows = []\n","    for start in range(0, n_times - win + 1, hop):\n","        windows.append(epoch[:, start:start+win])\n","    return np.stack(windows, axis=0)  # → (n_windows, n_chans, win)\n","\n","# ────────────────────────────────────────────────────────────────\n","# 3) LOAD & EXTRACT RAW TRIALS FROM .PTH\n","# ────────────────────────────────────────────────────────────────\n","\n","pth_file = r\"/content/drive/MyDrive/ImageNet_Images/EEG-ImageNet-full.pth\"\n","d = torch.load(pth_file, weights_only=False)\n","\n","trials = d[\"dataset\"]   # list of 63 850 dicts\n","wnids  = np.array([trial[\"label\"] for trial in trials])  # (63850,), dtype=object\n","images = np.array([trial[\"image\"] for trial in trials])\n","\n","print(\"Total trials:\", len(trials))        # → 63850\n","print(\"Unique labels:\", np.unique(wnids).shape[0])  # → 80\n","\n","# 4) PREPROCESS EVERY TRIAL (skip mastoid step)\n","sfreq_raw = 1000.0\n","sfreq_new = 250.0\n","\n","preprocessed_list, preprocessedVis_list, wnids_list, imgs_list, gran_list, sub_list = [], [], [], [],[],[]\n","for trial in trials:\n","    eeg_tensor = trial[\"eeg_data\"]  # shape (62, 501)\n","    if isinstance(eeg_tensor, torch.Tensor):\n","        raw_np = eeg_tensor.cpu().numpy()\n","    else:\n","        raw_np = np.asarray(eeg_tensor)\n","\n","    # Since the dataset has already discarded M1/M2, we do NOT call linked_mastoid_reference here.\n","    data_proc, data_proc_vis = preprocess_single_trial(\n","        raw_data=raw_np,\n","        sfreq_raw=sfreq_raw,\n","        notch_freq=(50.0,100.0,150.0),\n","        notch_bw=1.0,\n","        bp_low=0.5,\n","        bp_high=80.0,\n","        bp_order=5,\n","        tmin=0.04,\n","        tmax=0.44,\n","        sfreq_new=sfreq_new\n","    )\n","    windows = segment_windows(data_proc, win=64, hop=32)\n","    windows_vis = segment_windows(data_proc_vis, win=64, hop=32)\n","    assert len(windows) == len(windows_vis)\n","    n_w = len(windows)\n","    preprocessed_list.extend(windows)\n","    preprocessedVis_list.extend(windows_vis)\n","    wnids_list.extend([trial[\"label\"]]*n_w)\n","    imgs_list.extend([trial[\"image\"]]*n_w)\n","    gran_list.extend([trial[\"granularity\"]]*n_w)\n","    sub_list.extend([trial[\"subject\"]]*n_w)\n","\n","\n","# Stack into (n_trials, 62, n_times_new)\n","all_trials = np.stack(preprocessed_list, axis=0)\n","all_trials_vis = np.stack(preprocessedVis_list, axis=0)\n","wnids = np.array(wnids_list)                    # (N_total,)\n","imgs  = np.array(imgs_list)                     # (N_total,)\n","gran  = np.array(gran_list)                     # (N_total,)\n","sub  = np.array(sub_list, dtype=int)  # (N,)\n","\n","\n","# ────────────────────────────────────────────────────────────────\n","# 5) FOR EACH GRANULARITY: split & normalize & save\n","# ────────────────────────────────────────────────────────────────\n","\n","FINE_GROUPS = {\n","  \"fine0\": {\"n07753275\",\"n12144580\",\"n07772935\",\"n07756951\",\"n07740461\",\"n07749192\",\"n07758680\",\"n07745940\"},  # set of the 8 wnids in group0\n","  \"fine1\": {\"n03384352\",\"n02901620\",\"n04389033\",\"n04465666\",\"n03690473\",\"n03790512\",\"n02701002\",\"n03845190\"},\n","  \"fine2\": {\"n02107142\",\"n02110185\",\"n02111889\",\"n02099601\",\"n02112826\",\"n02106166\",\"n02099712\",\"n02106550\"},\n","  \"fine3\": {\"n04249415\",\"n03884397\",\"n02672831\",\"n03372029\",\"n02992211\",\"n04487394\",\"n03838899\",\"n03495258\"},\n","  \"fine4\": {\"n01494475\",\"n01456756\",\"n02643566\",\"n02630281\",\"n01484850\",\"n02655020\",\"n01496331\",\"n01443537\"},\n","\n","}\n","\n","coarse_wnids = [\n","    \"n02510455\",\"n02106662\",\"n03584829\",\"n02124075\",\"n13054560\",\"n03445777\",\n","    \"n04120489\",\"n02504458\",\"n02607072\",\"n03775071\",\"n04044716\",\"n04086273\",\n","    \"n02690373\",\"n02992529\",\"n11939491\",\"n03063599\",\"n03272562\",\"n03180011\",\n","    \"n03888257\",\"n07753592\",\"n03297495\",\"n03100240\",\"n02281787\",\"n02906734\",\n","    \"n02492035\",\"n03773504\",\"n07873807\",\"n03877472\",\"n03590841\",\"n03709823\",\n","    \"n02389026\",\"n02951358\",\"n03452741\",\"n04069434\",\"n03982430\",\"n03792782\",\n","    \"n03792972\",\"n03376595\",\"n03197337\",\"n03272010\"\n","]\n","\n","for ch in (\"all_channels\",):\n","  for g in (\"fine0\",\"fine1\",\"fine2\",\"fine3\",\"fine4\"):\n","      # a) filter\n","\n","      OUT_ROOT = f\"/content/drive/MyDrive/ImageNet_Images/preprocessed_splits/granularity/Time/{ch}/{g}\"\n","      os.makedirs(OUT_ROOT, exist_ok=True)\n","\n","\n","      if   g == \"all\":\n","          idx = np.arange(len(gran))\n","      elif g == \"coarse\":\n","          idx = (gran == \"coarse\") & np.isin(wnids, coarse_wnids)\n","      else:\n","          idx = (gran == \"fine\") & np.isin(wnids, list(FINE_GROUPS[g]))\n","\n","      if ch == \"all_channels\":\n","          specs_g = all_trials[idx]\n","      else:\n","          specs_g = all_trials_vis[idx]\n","\n","      wnids_g = wnids[idx]\n","      imgs_g  = imgs [idx]\n","      sub_g  = sub [idx]\n","      # b) unique‑image split\n","      unique_imgs, first = np.unique(imgs_g, return_index=True)\n","      uniq_wnids          = wnids_g[first]\n","      train_imgs, temp_imgs, _, temp_wnids = train_test_split(\n","          unique_imgs, uniq_wnids,\n","          test_size=0.05, stratify=uniq_wnids, random_state=42)\n","      val_imgs, test_imgs, _, _ = train_test_split(\n","          temp_imgs, temp_wnids,\n","          train_size=0.4, stratify=temp_wnids, random_state=42)\n","\n","      # build boolean masks\n","      is_train = np.isin(imgs_g, train_imgs)\n","      is_val   = np.isin(imgs_g, val_imgs)\n","      is_test  = np.isin(imgs_g, test_imgs)\n","\n","      Xtr, ytr, Itr,strain, trainFnames = specs_g[is_train], wnids_g[is_train], imgs_g[is_train],sub_g[is_train],imgs_g[is_train].tolist()\n","      Xva, yva, Iva,sva, vFnames = specs_g[is_val  ], wnids_g[is_val  ], imgs_g[is_val  ],sub_g[is_val  ],imgs_g[is_val].tolist()\n","      Xte, yte, Ite,ste, testFnames = specs_g[is_test ], wnids_g[is_test ], imgs_g[is_test ],sub_g[is_test ],imgs_g[is_test].tolist()\n","\n","      # c) standardize by Xtr only\n","      mu    = Xtr.mean(axis=(0, 2), keepdims=True)    # → (1, C, 1)\n","      sigma = Xtr.std( axis=(0, 2), keepdims=True) + 1e-7\n","\n","      Xtr_z = (Xtr - mu)   / sigma\n","      Xva_z = (Xva - mu)   / sigma\n","      Xte_z = (Xte - mu)   / sigma\n","\n","\n","\n","      def save_split(Xz, labels, images,subjects, split_name, imgFname):\n","\n","          tensor = torch.from_numpy(Xz.astype(np.float32)).unsqueeze(1)\n","          fname  = os.path.join(OUT_ROOT, f\"{split_name}_timeNewHop32.pt\")\n","          torch.save((tensor, labels, images,subjects, imgFname), fname)\n","\n","      save_split(Xtr_z, ytr, Itr,strain, \"train\",trainFnames)\n","      save_split(Xva_z, yva, Iva,sva, \"val\",vFnames)\n","      save_split(Xte_z, yte, Ite,ste, \"test\",testFnames)\n","\n","      print(f\"→ saved {g}: \"\n","            f\"train={Xtr_z.shape[0]}, val={Xva_z.shape[0]}, test={Xte_z.shape[0]}\")\n"]}]}