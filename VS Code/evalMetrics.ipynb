{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4","mount_file_id":"1Rd9dhgLnuC9sEXmpU10tEX29wZHOSn0y","authorship_tag":"ABX9TyOl4XwgfVPuq3YGt5WSFKiW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install git+https://github.com/openai/CLIP.git\n","!pip install git+https://github.com/richzhang/PerceptualSimilarity"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zg6rWcHBpsD_","executionInfo":{"status":"ok","timestamp":1755533308674,"user_tz":-60,"elapsed":89886,"user":{"displayName":"jay webb","userId":"02822891855666551694"}},"outputId":"0d3751f5-99eb-42e2-a7ed-4164e6f1fd62"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting git+https://github.com/openai/CLIP.git\n","  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-g6a_z4is\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-g6a_z4is\n","  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting ftfy (from clip==1.0)\n","  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (25.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (4.67.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (2.6.0+cu124)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from clip==1.0) (0.21.0+cu124)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->clip==1.0) (0.2.13)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (2025.3.0)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->clip==1.0)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->clip==1.0)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->clip==1.0)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->clip==1.0)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->clip==1.0)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->clip==1.0)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch->clip==1.0)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->clip==1.0)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->clip==1.0)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (0.6.2)\n","Collecting nvidia-nccl-cu12==2.21.5 (from torch->clip==1.0)\n","  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->clip==1.0)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->clip==1.0) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->clip==1.0) (1.3.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->clip==1.0) (11.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->clip==1.0) (3.0.2)\n","Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m91.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m95.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: clip\n","  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369490 sha256=a5a1c8e38a57cddeac11a072b7244f4cc3a8584f97b4d7ad887481b90dc97d7d\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-pds9__2b/wheels/3f/7c/a4/9b490845988bf7a4db33674d52f709f088f64392063872eb9a\n","Successfully built clip\n","Installing collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, clip\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-nccl-cu12\n","    Found existing installation: nvidia-nccl-cu12 2.23.4\n","    Uninstalling nvidia-nccl-cu12-2.23.4:\n","      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed clip-1.0 ftfy-6.3.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127\n","Collecting git+https://github.com/richzhang/PerceptualSimilarity\n","  Cloning https://github.com/richzhang/PerceptualSimilarity to /tmp/pip-req-build-nhh4h4mk\n","  Running command git clone --filter=blob:none --quiet https://github.com/richzhang/PerceptualSimilarity /tmp/pip-req-build-nhh4h4mk\n","  Resolved https://github.com/richzhang/PerceptualSimilarity to commit 082bb24f84c091ea94de2867d34c4544f68e0963\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from lpips==0.1.4) (2.6.0+cu124)\n","Requirement already satisfied: torchvision>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from lpips==0.1.4) (0.21.0+cu124)\n","Requirement already satisfied: numpy>=1.14.3 in /usr/local/lib/python3.11/dist-packages (from lpips==0.1.4) (2.0.2)\n","Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from lpips==0.1.4) (1.16.1)\n","Requirement already satisfied: tqdm>=4.28.1 in /usr/local/lib/python3.11/dist-packages (from lpips==0.1.4) (4.67.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips==0.1.4) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips==0.1.4) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips==0.1.4) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips==0.1.4) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips==0.1.4) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips==0.1.4) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips==0.1.4) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips==0.1.4) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips==0.1.4) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips==0.1.4) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips==0.1.4) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips==0.1.4) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips==0.1.4) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips==0.1.4) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips==0.1.4) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips==0.1.4) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips==0.1.4) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips==0.1.4) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips==0.1.4) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.0->lpips==0.1.4) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=0.4.0->lpips==0.1.4) (1.3.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision>=0.2.1->lpips==0.1.4) (11.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=0.4.0->lpips==0.1.4) (3.0.2)\n","Building wheels for collected packages: lpips\n","  Building wheel for lpips (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lpips: filename=lpips-0.1.4-py3-none-any.whl size=53704 sha256=7b9d81233bc3a0acb1928c7139b3ee38c3a33884adcd130cb867cb2f9616daf2\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-q4_m_sac/wheels/72/af/aa/888a9f31374852b5ec36482b1d21c323c090414b3b2a9b78f9\n","Successfully built lpips\n","Installing collected packages: lpips\n","Successfully installed lpips-0.1.4\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RyjQsfRVpVdt","executionInfo":{"status":"ok","timestamp":1755543694755,"user_tz":-60,"elapsed":10341401,"user":{"displayName":"jay webb","userId":"02822891855666551694"}},"outputId":"257b6531-c2ca-4b45-a7a1-925f69844bf9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n","100%|██████████| 528M/528M [00:02<00:00, 214MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["Loading model from: /usr/local/lib/python3.11/dist-packages/lpips/weights/v0.1/vgg.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|███████████████████████████████████████| 338M/338M [00:08<00:00, 40.0MiB/s]\n","ACGAN_reconstructions_fine0: 100%|██████████| 3/3 [01:17<00:00, 25.92s/batch]\n"]},{"output_type":"stream","name":"stdout","text":["Folder: ACGAN_reconstructions_fine0\n"," SSIM: 0.1943, PSNR: 8.52, LPIPS: 0.8986\n"," CLIP cos: 0.6182, 200-way ID: 16.5775%\n"," CAT: 17.1123%, CFID: 0.7648\n","\n"]},{"output_type":"stream","name":"stderr","text":["DCGAN_reconstructions_fine0: 100%|██████████| 3/3 [00:18<00:00,  6.31s/batch]\n"]},{"output_type":"stream","name":"stdout","text":["Folder: DCGAN_reconstructions_fine0\n"," SSIM: 0.2190, PSNR: 8.54, LPIPS: 0.8946\n"," CLIP cos: 0.6113, 200-way ID: 0.0000%\n"," CAT: 8.5561%, CFID: 0.7772\n","\n"]},{"output_type":"stream","name":"stderr","text":["cProGAN_reconstructions_fine0: 100%|██████████| 3/3 [00:19<00:00,  6.66s/batch]\n"]},{"output_type":"stream","name":"stdout","text":["Folder: cProGAN_reconstructions_fine0\n"," SSIM: 0.2010, PSNR: 8.27, LPIPS: 0.8839\n"," CLIP cos: 0.5957, 200-way ID: 8.5561%\n"," CAT: 27.8075%, CFID: 0.8081\n","\n"]},{"output_type":"stream","name":"stderr","text":["capsGAN_reconstructions_fine0: 100%|██████████| 3/3 [00:19<00:00,  6.58s/batch]\n"]},{"output_type":"stream","name":"stdout","text":["Folder: capsGAN_reconstructions_fine0\n"," SSIM: 0.2157, PSNR: 8.47, LPIPS: 0.9043\n"," CLIP cos: 0.5957, 200-way ID: 8.5561%\n"," CAT: 0.0000%, CFID: 0.8091\n","\n"]},{"output_type":"stream","name":"stderr","text":["ACGAN_reconstructions: 100%|██████████| 3/3 [01:16<00:00, 25.34s/batch]\n"]},{"output_type":"stream","name":"stdout","text":["Folder: ACGAN_reconstructions\n"," SSIM: 0.2091, PSNR: 10.60, LPIPS: 0.8010\n"," CLIP cos: 0.4844, 200-way ID: 3.1915%\n"," CAT: 7.9787%, CFID: 1.0267\n","\n"]},{"output_type":"stream","name":"stderr","text":["DCGAN_reconstructions: 100%|██████████| 3/3 [00:18<00:00,  6.04s/batch]\n"]},{"output_type":"stream","name":"stdout","text":["Folder: DCGAN_reconstructions\n"," SSIM: 0.2055, PSNR: 10.00, LPIPS: 0.8117\n"," CLIP cos: 0.5112, 200-way ID: 8.5106%\n"," CAT: 7.9787%, CFID: 0.9789\n","\n"]},{"output_type":"stream","name":"stderr","text":["cProGAN_reconstructions: 100%|██████████| 3/3 [00:17<00:00,  5.97s/batch]\n"]},{"output_type":"stream","name":"stdout","text":["Folder: cProGAN_reconstructions\n"," SSIM: 0.2403, PSNR: 10.75, LPIPS: 0.7807\n"," CLIP cos: 0.5713, 200-way ID: 21.8085%\n"," CAT: 0.0000%, CFID: 0.8578\n","\n"]},{"output_type":"stream","name":"stderr","text":["capsGAN_reconstructions: 100%|██████████| 3/3 [00:19<00:00,  6.65s/batch]\n"]},{"output_type":"stream","name":"stdout","text":["Folder: capsGAN_reconstructions\n"," SSIM: 0.1508, PSNR: 7.50, LPIPS: 0.8783\n"," CLIP cos: 0.4536, 200-way ID: 3.1915%\n"," CAT: 7.9787%, CFID: 1.0921\n","\n"]},{"output_type":"stream","name":"stderr","text":["ACGAN_reconstructions: 100%|██████████| 3/3 [01:32<00:00, 30.89s/batch]\n"]},{"output_type":"stream","name":"stdout","text":["Folder: ACGAN_reconstructions\n"," SSIM: 0.1887, PSNR: 9.21, LPIPS: 0.8487\n"," CLIP cos: 0.4963, 200-way ID: 8.1967%\n"," CAT: 16.3934%, CFID: 1.0078\n","\n"]},{"output_type":"stream","name":"stderr","text":["DCGAN_reconstructions: 100%|██████████| 3/3 [00:17<00:00,  5.97s/batch]\n"]},{"output_type":"stream","name":"stdout","text":["Folder: DCGAN_reconstructions\n"," SSIM: 0.1879, PSNR: 9.09, LPIPS: 0.8196\n"," CLIP cos: 0.5273, 200-way ID: 8.1967%\n"," CAT: 16.3934%, CFID: 0.9431\n","\n"]},{"output_type":"stream","name":"stderr","text":["cProGAN_reconstructions: 100%|██████████| 3/3 [00:17<00:00,  5.91s/batch]\n"]},{"output_type":"stream","name":"stdout","text":["Folder: cProGAN_reconstructions\n"," SSIM: 0.2036, PSNR: 9.04, LPIPS: 0.8302\n"," CLIP cos: 0.5464, 200-way ID: 8.1967%\n"," CAT: 16.3934%, CFID: 0.9087\n","\n"]},{"output_type":"stream","name":"stderr","text":["capsGAN_reconstructions: 100%|██████████| 3/3 [00:19<00:00,  6.61s/batch]\n"]},{"output_type":"stream","name":"stdout","text":["Folder: capsGAN_reconstructions\n"," SSIM: 0.1347, PSNR: 7.54, LPIPS: 0.8732\n"," CLIP cos: 0.5156, 200-way ID: 16.3934%\n"," CAT: 16.3934%, CFID: 0.9665\n","\n"]},{"output_type":"stream","name":"stderr","text":["ACGAN_reconstructions: 100%|██████████| 15/15 [03:29<00:00, 13.96s/batch]\n"]},{"output_type":"stream","name":"stdout","text":["Folder: ACGAN_reconstructions\n"," SSIM: 0.2407, PSNR: 8.64, LPIPS: 0.8241\n"," CLIP cos: 0.5762, 200-way ID: 1.6146%\n"," CAT: 1.6146%, CFID: 0.8300\n","\n"]},{"output_type":"stream","name":"stderr","text":["DCGAN_reconstructions: 100%|██████████| 15/15 [01:37<00:00,  6.50s/batch]\n"]},{"output_type":"stream","name":"stdout","text":["Folder: DCGAN_reconstructions\n"," SSIM: 0.2261, PSNR: 8.22, LPIPS: 0.8332\n"," CLIP cos: 0.5630, 200-way ID: 1.7761%\n"," CAT: 24.4349%, CFID: 0.8504\n","\n"]},{"output_type":"stream","name":"stderr","text":["cProGAN_reconstructions: 100%|██████████| 15/15 [01:36<00:00,  6.46s/batch]\n"]},{"output_type":"stream","name":"stdout","text":["Folder: cProGAN_reconstructions\n"," SSIM: 0.2746, PSNR: 8.29, LPIPS: 0.7603\n"," CLIP cos: 0.5684, 200-way ID: 0.2153%\n"," CAT: 11.3025%, CFID: 0.8580\n","\n"]},{"output_type":"stream","name":"stderr","text":["capsGAN_reconstructions: 100%|██████████| 15/15 [01:45<00:00,  7.04s/batch]\n"]},{"output_type":"stream","name":"stdout","text":["Folder: capsGAN_reconstructions\n"," SSIM: 0.2362, PSNR: 8.14, LPIPS: 0.8428\n"," CLIP cos: 0.5547, 200-way ID: 0.0538%\n"," CAT: 8.0732%, CFID: 0.8712\n","\n"]},{"output_type":"stream","name":"stderr","text":["ACGAN_reconstructions_fine4: 100%|██████████| 3/3 [01:12<00:00, 24.02s/batch]\n"]},{"output_type":"stream","name":"stdout","text":["Folder: ACGAN_reconstructions_fine4\n"," SSIM: 0.2355, PSNR: 10.24, LPIPS: 0.7750\n"," CLIP cos: 0.5654, 200-way ID: 16.3934%\n"," CAT: 8.1967%, CFID: 0.8689\n","\n"]},{"output_type":"stream","name":"stderr","text":["DCGAN_reconstructions_fine4: 100%|██████████| 3/3 [00:18<00:00,  6.09s/batch]\n"]},{"output_type":"stream","name":"stdout","text":["Folder: DCGAN_reconstructions_fine4\n"," SSIM: 0.1952, PSNR: 8.93, LPIPS: 0.8435\n"," CLIP cos: 0.5557, 200-way ID: 0.0000%\n"," CAT: 8.1967%, CFID: 0.8881\n","\n"]},{"output_type":"stream","name":"stderr","text":["cProGAN_reconstructions_fine4: 100%|██████████| 3/3 [00:18<00:00,  6.28s/batch]\n"]},{"output_type":"stream","name":"stdout","text":["Folder: cProGAN_reconstructions_fine4\n"," SSIM: 0.2512, PSNR: 10.14, LPIPS: 0.7676\n"," CLIP cos: 0.5708, 200-way ID: 16.3934%\n"," CAT: 8.1967%, CFID: 0.8588\n","\n"]},{"output_type":"stream","name":"stderr","text":["capsGAN_reconstructions_fine4: 100%|██████████| 3/3 [00:20<00:00,  6.83s/batch]\n"]},{"output_type":"stream","name":"stdout","text":["Folder: capsGAN_reconstructions_fine4\n"," SSIM: 0.2026, PSNR: 8.83, LPIPS: 0.8699\n"," CLIP cos: 0.5303, 200-way ID: 8.1967%\n"," CAT: 8.1967%, CFID: 0.9385\n","\n"]},{"output_type":"stream","name":"stderr","text":["ACGAN_reconstructions: 100%|██████████| 37/37 [14:23<00:00, 23.34s/batch]\n"]},{"output_type":"stream","name":"stdout","text":["Folder: ACGAN_reconstructions\n"," SSIM: 0.1940, PSNR: 9.42, LPIPS: 0.8262\n"," CLIP cos: 0.5430, 200-way ID: 1.2956%\n"," CAT: 2.5912%, CFID: 0.9127\n","\n"]},{"output_type":"stream","name":"stderr","text":["DCGAN_reconstructions: 100%|██████████| 37/37 [05:24<00:00,  8.77s/batch]\n"]},{"output_type":"stream","name":"stdout","text":["Folder: DCGAN_reconstructions\n"," SSIM: 0.2004, PSNR: 8.39, LPIPS: 0.8638\n"," CLIP cos: 0.5420, 200-way ID: 0.6910%\n"," CAT: 1.6195%, CFID: 0.8847\n","\n"]},{"output_type":"stream","name":"stderr","text":["cProGAN_reconstructions: 100%|██████████| 37/37 [05:21<00:00,  8.69s/batch]\n"]},{"output_type":"stream","name":"stdout","text":["Folder: cProGAN_reconstructions\n"," SSIM: 0.2206, PSNR: 8.99, LPIPS: 0.8322\n"," CLIP cos: 0.5503, 200-way ID: 0.9069%\n"," CAT: 2.5912%, CFID: 0.8937\n","\n"]},{"output_type":"stream","name":"stderr","text":["capsGAN_reconstructions: 100%|██████████| 37/37 [06:08<00:00,  9.97s/batch]\n"]},{"output_type":"stream","name":"stdout","text":["Folder: capsGAN_reconstructions\n"," SSIM: 0.1876, PSNR: 8.52, LPIPS: 0.8633\n"," CLIP cos: 0.5366, 200-way ID: 0.0648%\n"," CAT: 2.5912%, CFID: 0.9046\n","\n"]}],"source":["\"\"\"\n","================================\n","Batch-evaluate multiple reconstruction folders against EEG-ImageNet ground truth.\n","\n","For each subfolder under `test_results_dir`, it computes:\n","  - SSIM, PSNR, LPIPS\n","  - CLIP cosine, n-way identification accuracy\n","  - CAT score\n","  - CFID\n","\n","\"\"\"\n","from __future__ import annotations\n","import os, glob, csv, math\n","from pathlib import Path\n","from typing import Dict, List, Tuple\n","from scipy.linalg import sqrtm as scipy_sqrtm\n","\n","import numpy as np\n","import torch\n","import torch.nn.functional as F\n","from PIL import Image\n","from skimage.metrics import structural_similarity as ssim\n","from tqdm import tqdm\n","\n","import lpips\n","import clip\n","\n","# ----------------------------- setup -----------------------------\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# create once (saves time)\n","lpips_model = lpips.LPIPS(net=\"vgg\").to(device)\n","clip_model, _ = clip.load(\"ViT-B/32\", device=device)\n","\n","# ----------------------------- utils -----------------------------\n","\n","def load_image(path: str | Path, size: int = 224) -> torch.Tensor:\n","    \"\"\"Load RGB image → tensor in [-1,1], resized to `size`.\"\"\"\n","    img = Image.open(path).convert(\"RGB\").resize((size, size), Image.BICUBIC)\n","    arr = np.asarray(img).astype(np.float32) / 127.5 - 1.0\n","    return torch.from_numpy(arr).permute(2, 0, 1)\n","\n","def mse2psnr(mse: float, max_val: float = 255.0) -> float:\n","    return 10.0 * math.log10((max_val**2) / (mse + 1e-10))\n","\n","def compute_ssim_psnr(real_imgs: torch.Tensor, recon_imgs: torch.Tensor) -> Tuple[float, float]:\n","    \"\"\"Return batch means of SSIM and PSNR. Inputs in [-1,1], shape (B,C,H,W).\"\"\"\n","    assert real_imgs.shape == recon_imgs.shape\n","    real_np  = (real_imgs.detach().cpu().numpy() + 1) * 127.5\n","    recon_np = (recon_imgs.detach().cpu().numpy() + 1) * 127.5\n","    s_vals, p_vals = [], []\n","    for gt, rn in zip(real_np, recon_np):\n","        s_val = ssim(gt.transpose(1, 2, 0), rn.transpose(1, 2, 0),\n","                     channel_axis=2, data_range=255)\n","        s_vals.append(s_val)\n","        mse = np.mean((gt - rn) ** 2)\n","        p_vals.append(mse2psnr(mse))\n","    return float(np.mean(s_vals)), float(np.mean(p_vals))\n","\n","def embed_images_clip(img_batch: torch.Tensor, clip_model) -> torch.Tensor:\n","    \"\"\"Encode a batch of images in [-1,1] with CLIP ViT-B/32 → L2-normalized feats.\"\"\"\n","    imgs = (img_batch + 1) / 2\n","    imgs = F.interpolate(imgs, size=(224, 224), mode=\"bicubic\", align_corners=False)\n","    clip_mean = torch.tensor([0.48145466, 0.4578275, 0.40821073], device=imgs.device).view(1, 3, 1, 1)\n","    clip_std  = torch.tensor([0.26862954, 0.26130258, 0.27577711], device=imgs.device).view(1, 3, 1, 1)\n","    imgs_norm = (imgs - clip_mean) / clip_std\n","    with torch.no_grad():\n","        feats = clip_model.encode_image(imgs_norm)\n","    return F.normalize(feats, dim=-1)\n","\n","def compute_clip_cosine(real_feats: torch.Tensor, recon_feats: torch.Tensor) -> float:\n","    cos = (real_feats * recon_feats).sum(dim=-1)\n","    return float(cos.mean().cpu())\n","\n","def identification_accuracy(recon_feats: torch.Tensor,\n","                            real_feats: torch.Tensor,\n","                            n_way: int = 200,\n","                            rnd_seed: int = 42) -> float:\n","    \"\"\"n-way image identification accuracy using cosine similarity.\"\"\"\n","    np.random.seed(rnd_seed)\n","    num = recon_feats.size(0)\n","    hits = 0\n","    feat_np  = real_feats.cpu().numpy()\n","    recon_np = recon_feats.cpu().numpy()\n","    for i in range(num):\n","        idx_pool = np.delete(np.arange(num), i)\n","        k = min(n_way - 1, len(idx_pool))\n","        distractors = np.random.choice(idx_pool, size=k, replace=False)\n","        cand_idx = np.concatenate(([i], distractors))\n","        sims = recon_np[i] @ feat_np[cand_idx].T\n","        pred = cand_idx[np.argmax(sims)]\n","        hits += int(pred == i)\n","    return hits / num\n","\n","def cat_score(pred_labels: List[str], true_fine: List[str], fine2coarse: Dict[str, str]) -> float:\n","    true_coarse = [fine2coarse[f] for f in true_fine]\n","    pred_coarse = [fine2coarse[p] for p in pred_labels]\n","    fine_acc   = np.mean([p == t for p, t in zip(pred_labels, true_fine)])\n","    coarse_acc = np.mean([p == t for p, t in zip(pred_coarse, true_coarse)])\n","    return float((fine_acc + coarse_acc) / 2.0)\n","\n","# -------- CFID helpers --------\n","\n","def frechet_distance(mu1: torch.Tensor,\n","                     sigma1: torch.Tensor,\n","                     mu2: torch.Tensor,\n","                     sigma2: torch.Tensor) -> float:\n","    \"\"\"\n","    Fréchet distance between N(mu1, sigma1) and N(mu2, sigma2).\n","    Uses scipy.linalg.sqrtm on CPU float32 for stability.\n","    \"\"\"\n","    diff = (mu1 - mu2).cpu().numpy()\n","    diff_sq = float(diff.dot(diff))\n","\n","    s1 = sigma1.float().cpu()\n","    s2 = sigma2.float().cpu()\n","    tr1 = float(torch.trace(s1).item())\n","    tr2 = float(torch.trace(s2).item())\n","\n","    cov_prod = (s1 @ s2).numpy()\n","    cov_sqrt = scipy_sqrtm(cov_prod)\n","    if np.iscomplexobj(cov_sqrt):\n","        cov_sqrt = cov_sqrt.real\n","    tr_cov_sqrt = float(np.trace(cov_sqrt))\n","\n","    return diff_sq + tr1 + tr2 - 2 * tr_cov_sqrt\n","\n","def compute_cfid(real_feats: torch.Tensor,\n","                 recon_feats: torch.Tensor,\n","                 labels: List[str]) -> float:\n","    \"\"\"Conditional FID averaged across classes (skipping tiny classes).\"\"\"\n","    labels_np = np.array(labels)\n","    classes = np.unique(labels_np)\n","    dists, weights = [], []\n","    for cls in classes:\n","        idx = np.where(labels_np == cls)[0]\n","        if len(idx) < 10:\n","            continue\n","        r = real_feats[idx]\n","        f = recon_feats[idx]\n","        mu_r, mu_f = r.mean(0), f.mean(0)\n","        d = r.shape[1]\n","        eps = 1e-6\n","        I = torch.eye(d)\n","        sigma_r = torch.cov(r.T).float() + eps * I\n","        sigma_f = torch.cov(f.T).float() + eps * I\n","        d_cf = frechet_distance(mu_r, sigma_r, mu_f, sigma_f)\n","        dists.append(d_cf)\n","        weights.append(len(idx))\n","    return float(np.average(dists, weights=weights)) if dists else float(\"nan\")\n","\n","# ------------------------- evaluation core -------------------------\n","\n","def evaluate_folder(real_dir: str,\n","                    recon_dir: str,\n","                    labels_csv: str,\n","                    n_id: int = 200,\n","                    device: str = \"cuda\",\n","                    batch_size: int = 128):\n","    # ---- read CSV (order matters) ----\n","    fnames, fine_labels, fine2coarse = [], [], {}\n","    with open(labels_csv) as f:\n","        rdr = csv.DictReader(f)\n","        for r in rdr:\n","            fnames.append(r[\"filename\"])\n","            fine_labels.append(r[\"fine_label\"])\n","            fine2coarse[r[\"fine_label\"]] = r[\"coarse_label\"]\n","\n","    # ---- build real & recon paths from CSV order ----\n","    real_paths = [os.path.join(real_dir, fine_labels[i], fnames[i]) for i in range(len(fnames))]\n","\n","    # recon files can be nested and include subject suffix; match by base name + wildcard\n","    recon_paths: List[str] = []\n","    for real_fname in fnames:\n","        base = os.path.splitext(real_fname)[0]  # e.g. \"n02655020_3570\"\n","        found: List[str] = []\n","        for ext in (\"png\", \"jpg\", \"jpeg\", \"PNG\", \"JPG\", \"JPEG\"):\n","            found += glob.glob(os.path.join(recon_dir, \"**\", f\"{base}_*.{ext}\"), recursive=True)\n","        if not found:\n","            raise FileNotFoundError(f\"No reconstruction found for {base} under {recon_dir}\")\n","        recon_paths.append(sorted(found)[0])  # pick the first match (or choose by subject)\n","\n","    assert len(real_paths) == len(recon_paths), \"1-to-1 alignment failed.\"\n","\n","    # ---- accumulators (weighted by batch size) ----\n","    n_imgs = 0\n","    ssim_sum = 0.0\n","    psnr_sum = 0.0\n","    lpips_sum = 0.0\n","    real_feats_list, recon_feats_list = [], []\n","\n","    # ---- loop ----\n","    total_batches = (len(real_paths) + batch_size - 1) // batch_size\n","    for start in tqdm(range(0, len(real_paths), batch_size),\n","                      total=total_batches,\n","                      unit=\"batch\",\n","                      desc=os.path.basename(recon_dir)):\n","        rp = real_paths[start:start + batch_size]\n","        gp = recon_paths[start:start + batch_size]\n","        batch_real = torch.stack([load_image(p) for p in rp]).to(device)\n","        batch_recon = torch.stack([load_image(p) for p in gp]).to(device)\n","        bsz = batch_real.size(0)\n","\n","        # SSIM & PSNR (batch means)\n","        sr, pr = compute_ssim_psnr(batch_real, batch_recon)\n","        ssim_sum += sr * bsz\n","        psnr_sum += pr * bsz\n","\n","        # LPIPS\n","        with torch.no_grad():\n","            d = lpips_model(batch_recon, batch_real).view(-1).mean().item()\n","        lpips_sum += d * bsz\n","\n","        # CLIP features\n","        fr = embed_images_clip(batch_real, clip_model)\n","        fg = embed_images_clip(batch_recon, clip_model)\n","        real_feats_list.append(fr.cpu())\n","        recon_feats_list.append(fg.cpu())\n","\n","        n_imgs += bsz\n","\n","    # ---- aggregate ----\n","    real_feats = torch.cat(real_feats_list, dim=0)\n","    recon_feats = torch.cat(recon_feats_list, dim=0)\n","    SSIM  = ssim_sum / n_imgs\n","    PSNR  = psnr_sum / n_imgs\n","    LPIPS = lpips_sum / n_imgs\n","\n","    # ---- semantic / distribution metrics ----\n","    clip_cos = compute_clip_cosine(real_feats, recon_feats)\n","    id_acc   = identification_accuracy(recon_feats, real_feats, n_way=n_id)\n","\n","    with torch.no_grad():\n","        label_list = list(fine2coarse.keys())\n","        text_tokens = clip.tokenize(label_list).to(device)\n","        text_feats = clip_model.encode_text(text_tokens)\n","        text_feats = F.normalize(text_feats, dim=-1)\n","        sims = recon_feats.to(device) @ text_feats.T\n","        pred_idx = sims.argmax(dim=-1).cpu().numpy()\n","        pred_labels = [label_list[i] for i in pred_idx]\n","\n","    cat = cat_score(pred_labels, fine_labels, fine2coarse)\n","    cfid_val = compute_cfid(real_feats, recon_feats, fine_labels)\n","\n","    # ---- report ----\n","    print(f\"Folder: {os.path.basename(recon_dir)}\")\n","    print(f\" SSIM: {SSIM:.4f}, PSNR: {PSNR:.2f}, LPIPS: {LPIPS:.4f}\")\n","    print(f\" CLIP cos: {clip_cos:.4f}, {n_id}-way ID: {id_acc*100:.4f}%\")\n","    print(f\" CAT: {cat*100:.4f}%, CFID: {cfid_val:.4f}\\n\")\n","\n","# ----------------------------- runner -----------------------------\n","\n","if __name__ == \"__main__\":\n","    # Example multi-split sweep:\n","    for g in [\"fine0\", \"fine1\", \"fine2\", \"fine3\", \"fine4\", \"coarse\"]:\n","        real_dir = \"/content/drive/MyDrive/ImageNet_Images/images_80class\"\n","        labels_csv = f\"/content/drive/MyDrive/ImageNet_Images/latent_dumps/granularity/Time/all_channels/{g}/eeg_imagenet_test_labels.csv\"\n","        test_results_dir = f\"/content/drive/MyDrive/ImageNet_Images/testResults/Time/{g}\"\n","\n","        for sub in sorted(os.listdir(test_results_dir)):\n","            p = os.path.join(test_results_dir, sub)\n","            if os.path.isdir(p):\n","                evaluate_folder(real_dir, p, labels_csv, n_id=200, device=device, batch_size=128)\n"]}]}